# Duong AI Trading Pro - Environment Configuration
# Copy this file to .env and fill in your API keys

# === LLM API Keys ===
# Google Gemini AI (Free tier - 15 requests/minute)
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI GPT (Paid API)
OPENAI_API_KEY=your_openai_api_key_here

# Meta Llama - Multiple Options:
# Option 1: Ollama Local (FREE, no API key needed)
# Just run: ollama serve && ollama pull llama3.1:8b
# LLAMA_BASE_URL=http://localhost:11434

# Option 2: Groq API (Free tier - 30 requests/minute)
LLAMA_API_KEY=your_groq_api_key_here
LLAMA_BASE_URL=https://api.groq.com/openai/v1

# Option 3: Together AI (Free tier available)
# LLAMA_API_KEY=your_together_ai_api_key_here
# LLAMA_BASE_URL=https://api.together.xyz/v1

# === News & Data APIs ===
# Serper API for real news (Optional)
SERPER_API_KEY=your_serper_api_key_here

# === API Key Sources ===
# Gemini: https://aistudio.google.com/apikey
# OpenAI: https://platform.openai.com/api-keys
# Ollama: https://ollama.ai (local installation)
# Groq: https://groq.com (for fast Llama inference)
# Together AI: https://together.ai (for Llama)
# Serper: https://serper.dev/api-key

# === Ollama Local Setup ===
# 1. Install: https://ollama.ai
# 2. Run: ollama serve
# 3. Pull model: ollama pull llama3.1:8b
# 4. Test: python test_ollama_local.py

# === Usage Notes ===
# - At least 1 LLM is required (Gemini OR Llama OR OpenAI)
# - Ollama local is RECOMMENDED (free, fast, private)
# - Gemini is good for free cloud usage
# - OpenAI provides best quality but costs money
# - System will auto-fallback between available models